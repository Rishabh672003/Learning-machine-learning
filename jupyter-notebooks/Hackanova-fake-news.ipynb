{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC8tlBYGJXp6"
      },
      "source": [
        "# Get the data from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-yQ0DPSIL3y"
      },
      "outputs": [],
      "source": [
        "### This requires an API token .json file from kaggle\n",
        "\n",
        "### get it from going to https://www.kaggle.com/settings/account and clicking `create new token`\n",
        "\n",
        "### Then place the token .json file in your google drive, and copy the location in `kaggle_creds_path` variable and command below it\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "kaggle_creds_path = \"/content/drive/MyDrive/Kaggle/kaggle.json\"\n",
        "! cp /content/drive/MyDrive/Kaggle/kaggle.json .\n",
        "\n",
        "! pip install kaggle --quiet\n",
        "\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d saurabhshahane/fake-news-classification\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "location = '/content/fake-news-classification'\n",
        "zip_ref = zipfile.ZipFile(location+'.zip', 'r')\n",
        "\n",
        "if os.path.isdir(location):\n",
        "    shutil.rmtree(location)\n",
        "    os.mkdir(location)\n",
        "else:\n",
        "    os.mkdir(location)\n",
        "\n",
        "zip_ref.extractall(location)\n",
        "zip_ref.close()\n",
        "\n",
        "# Unmount your Google Drive\n",
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cRzuXeMMQFe"
      },
      "source": [
        "# Actual code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlJjYCrcMUzW"
      },
      "outputs": [],
      "source": [
        "#importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib.pylab import plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXJqS7UDiSn7"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/fake-news-classification/WELFake_Dataset.csv')\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4_UnFyQigw9"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocgU9oubiojR"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npzU2AsfiqFp"
      },
      "outputs": [],
      "source": [
        "y = df.label\n",
        "print(f'Ratio of real and fake news:')\n",
        "y.value_counts(normalize=True).rename({1: 'real', 0: 'fake'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVtC_azbitzA"
      },
      "outputs": [],
      "source": [
        "df.drop([\"Unnamed: 0\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-Rp2bCTix4F"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum().plot(kind=\"barh\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEs-3O5Ti5OK"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOMsZuyMi9c0"
      },
      "outputs": [],
      "source": [
        "df = df.fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehleTYY2jBZ_"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQz-n3X1jDhf"
      },
      "outputs": [],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PjLmF3PjFov"
      },
      "outputs": [],
      "source": [
        "df[\"title_text\"] = df[\"title\"] + df[\"text\"]\n",
        "df[\"body_len\"] = df[\"title_text\"].apply(lambda x: len(x) - x.count(\" \"))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4U66CwzjMfq"
      },
      "outputs": [],
      "source": [
        "bins = np.linspace(0, 200, 40)\n",
        "\n",
        "plt.hist(df[df[\"label\"]== 1][\"body_len\"], bins, alpha=0.5, label=\"Fake\", color=\"#FF5733\")\n",
        "plt.hist(df[df[\"label\"]== 0][\"body_len\"], bins, alpha=0.5, label=\"Real\", color=\"#33FFB8\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiHpkDA4jVn4"
      },
      "outputs": [],
      "source": [
        "class_names = ['fake', 'real']\n",
        "label_count = df.label.value_counts()\n",
        "sns.barplot(x=label_count.index, y=label_count)\n",
        "plt.title('Distribution of Fake/Real News',fontsize =14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a12Bgj6cjbH1"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.33, random_state=53)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao0TXlGFjepJ"
      },
      "outputs": [],
      "source": [
        "titles = ' '.join(title for title in df['title'])\n",
        "wordcloud = WordCloud(\n",
        "    background_color='white',\n",
        "    max_words=300,\n",
        "    width=800,\n",
        "    height=400,\n",
        ").generate(titles)\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkwJiqpajiIT"
      },
      "outputs": [],
      "source": [
        "fake_news = X_train[y_train == 0]\n",
        "real_news = X_train[y_train == 1]\n",
        "fake_texts = ' '.join(text for text in fake_news)\n",
        "wordcloud = WordCloud(\n",
        "    background_color='white',\n",
        "    max_words=300,\n",
        "    width=800,\n",
        "    height=400,\n",
        ").generate(fake_texts)\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcLpIMTxj-vv"
      },
      "outputs": [],
      "source": [
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "count_train = count_vectorizer.fit_transform(X_train)\n",
        "count_test = count_vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnsdfvxljmKZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=300)\n",
        "model.fit(count_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUKamqZckT6u"
      },
      "outputs": [],
      "source": [
        "pred2 = model.predict(count_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "eC8tlBYGJXp6"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}